{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pm/r8fcp13s1gqgh20ly21fl73c0000gn/T/ipykernel_673/3851847414.py:2: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/c10/core/TensorImpl.h:1903.)\n",
      "  _ = torch.tensor([0.2126,0.7152,0.0722],names=['c'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "_ = torch.tensor([0.2126,0.7152,0.0722],names=['c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_t = torch.randn(3, 5, 5)\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.1272e+00, -1.3753e+00, -2.6807e-01,  1.2215e+00,  1.7771e+00],\n",
       "          [-9.3588e-01,  1.8332e+00, -1.2846e-02, -1.0666e+00,  8.5603e-02],\n",
       "          [-1.4984e+00,  1.1661e-02,  2.2387e-01, -1.7384e+00,  1.3493e-01],\n",
       "          [-7.5744e-01, -2.2568e+00,  9.5576e-01,  9.3379e-01,  1.1772e-01],\n",
       "          [ 3.7500e-01,  2.1418e-01, -4.6588e-01,  6.6081e-01, -7.6724e-02]],\n",
       " \n",
       "         [[-6.9707e-01, -1.8235e+00,  1.5044e-01,  1.7496e+00,  1.9529e+00],\n",
       "          [-8.0582e-01, -1.5654e+00, -7.9424e-02,  8.6918e-01, -2.1225e-03],\n",
       "          [-1.4000e+00,  4.1336e-01,  1.2106e-01,  1.8831e+00,  5.3953e-02],\n",
       "          [-7.0884e-01, -2.0445e-01, -7.7414e-01, -4.8586e-01,  4.8557e-01],\n",
       "          [ 1.3950e+00, -1.7218e+00,  5.3339e-01,  5.4800e-01, -9.5955e-01]],\n",
       " \n",
       "         [[ 5.2953e-01,  7.8256e-01,  4.0723e-01, -5.6411e-01,  5.7865e-01],\n",
       "          [ 1.5167e+00, -1.3103e+00,  5.6275e-01, -1.2217e-01,  2.0087e+00],\n",
       "          [-2.4280e-01, -1.7443e+00, -1.4551e+00,  7.1391e-01, -5.2855e-01],\n",
       "          [ 1.6756e+00,  6.8832e-02, -2.8855e-01,  6.7355e-01, -3.4247e-01],\n",
       "          [ 3.5358e-01, -1.4656e+00, -1.1164e+00, -1.1440e-01, -5.9019e-01]]]),\n",
       " tensor([0.2126, 0.7152, 0.0722]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_t, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]\n",
    "image_gray_naive = image_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "image_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4316, -0.8054,  0.0965,  0.8023,  1.4362],\n",
       "        [-0.0750, -0.3475,  0.1568, -0.1065,  0.6974],\n",
       "        [-1.0471, -0.4398, -0.3701,  0.2862, -0.1132],\n",
       "        [ 0.0698, -0.7975, -0.0356,  0.3738,  0.0869],\n",
       "        [ 0.7078, -0.9911, -0.3496,  0.3648, -0.5422]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gray_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_small = torch.tensor([[[1.,2.],[3.,4.]], \n",
    "                            [[6.,6.],[7.,8.]], \n",
    "                            [[9.,10.],[11.,12.]]])\n",
    "image_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3333, 6.0000],\n",
       "        [7.0000, 8.0000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_small_gray_naive = image_small.mean(-3)\n",
    "image_small_gray_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2126]],\n",
       "\n",
       "        [[0.7152]],\n",
       "\n",
       "        [[0.0722]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "unsqueezed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlwpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
