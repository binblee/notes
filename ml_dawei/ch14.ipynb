{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33.  0.  0.  1.]\n",
      " [32.  0.  1.  0.]\n",
      " [40.  1.  0.  0.]]\n",
      "['age' 'name=大牛' 'name=张小小' 'name=李大龙']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "samples = [{'name':'李大龙','age':33},\n",
    "           {'name':'张小小','age':32},\n",
    "           {'name':'大牛','age':40}]\n",
    "vec = DictVectorizer()\n",
    "print(vec.fit_transform(samples).toarray())\n",
    "print(vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am sure some bashers of Pens fans are pretty confused about the lackof any kind of posts about the recent Pens massacre of the Devils',\n",
       " ' Actually,I am  bit puzzled too and a bit relieved',\n",
       " \" However, I am going to put an endto non-PIttsburghers' relief with a bit of praise for the Pens\",\n",
       " ' Man, theyare killing those Devils worse than I thought',\n",
       " ' Jagr just showed you whyhe is much better than his regular season stats',\n",
       " ' He is also a lotfo fun to watch in the playoffs',\n",
       " ' Bowman should let JAgr have a lot offun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway',\n",
       " ' I was very disappointed not to see the Islanders lose the finalregular season game',\n",
       " '          PENS RULE!!!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''\n",
    "I am sure some bashers of Pens fans are pretty confused about the lack\n",
    "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
    "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
    "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
    "are killing those Devils worse than I thought. Jagr just showed you why\n",
    "he is much better than his regular season stats. He is also a lot\n",
    "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
    "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
    "regular season game.          PENS RULE!!!\n",
    "'''\n",
    "text = text.replace('\\n','')\n",
    "corpus = [t for t in text.split('.')]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about' 'actually' 'also' 'am' 'an' 'and' 'any' 'anyway' 'are' 'bashers'\n",
      " 'beat' 'better' 'bit' 'bowman' 'confused' 'couple' 'devils'\n",
      " 'disappointed' 'endto' 'fans' 'finalregular' 'for' 'fun' 'game' 'games'\n",
      " 'going' 'have' 'he' 'his' 'however' 'in' 'is' 'islanders' 'jagr' 'jersey'\n",
      " 'just' 'killing' 'kind' 'lackof' 'let' 'lose' 'lot' 'lotfo' 'man'\n",
      " 'massacre' 'much' 'next' 'non' 'not' 'of' 'offun' 'out' 'pens'\n",
      " 'pittsburghers' 'playoffs' 'posts' 'praise' 'pretty' 'pulp' 'put'\n",
      " 'puzzled' 'recent' 'regular' 'relief' 'relieved' 'rule' 'season' 'see'\n",
      " 'should' 'showed' 'since' 'some' 'stats' 'sure' 'than' 'the' 'theyare'\n",
      " 'those' 'thought' 'to' 'too' 'very' 'was' 'watch' 'whyhe' 'with' 'worse'\n",
      " 'you']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "features = vec.fit_transform(corpus)\n",
    "print(vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'am': 3, 'sure': 73, 'some': 71, 'bashers': 9, 'of': 49, 'pens': 52, 'fans': 19, 'are': 8, 'pretty': 57, 'confused': 14, 'about': 0, 'the': 75, 'lackof': 38, 'any': 6, 'kind': 37, 'posts': 55, 'recent': 61, 'massacre': 44, 'devils': 16, 'actually': 1, 'bit': 12, 'puzzled': 60, 'too': 80, 'and': 5, 'relieved': 64, 'however': 29, 'going': 25, 'to': 79, 'put': 59, 'an': 4, 'endto': 18, 'non': 47, 'pittsburghers': 53, 'relief': 63, 'with': 85, 'praise': 56, 'for': 21, 'man': 43, 'theyare': 76, 'killing': 36, 'those': 77, 'worse': 86, 'than': 74, 'thought': 78, 'jagr': 33, 'just': 35, 'showed': 69, 'you': 87, 'whyhe': 84, 'is': 31, 'much': 45, 'better': 11, 'his': 28, 'regular': 62, 'season': 66, 'stats': 72, 'he': 27, 'also': 2, 'lotfo': 42, 'fun': 22, 'watch': 83, 'in': 30, 'playoffs': 54, 'bowman': 13, 'should': 68, 'let': 39, 'have': 26, 'lot': 41, 'offun': 50, 'next': 46, 'couple': 15, 'games': 24, 'since': 70, 'beat': 10, 'pulp': 58, 'out': 51, 'jersey': 34, 'anyway': 7, 'was': 82, 'very': 81, 'disappointed': 17, 'not': 48, 'see': 67, 'islanders': 32, 'lose': 40, 'finalregular': 20, 'game': 23, 'rule': 65}\n"
     ]
    }
   ],
   "source": [
    "print(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 1 0 0 0 0 0 1 0 0 0 0 3 0 0 2 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      "  0 1 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1\n",
      "  0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0\n",
      "  1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0\n",
      "  0 0 0 1 0 1 0 0 0 0 1 0 0 2 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      "  0 0 0 3 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      "  0 0 0 2 0 0 0 1 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#字符串中对应词典序号的词汇的词频\n",
    "print(features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  1  1  3  1  1  1  1  2  1  1  1  3  1  1  1  2  1  1  1  1  1  1  1\n",
      "  1  2  1  1  1  1  2  2  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  6  1  1  5  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  1  1  1  1\n",
      "  1  1  2 10  1  1  1  4  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "#每个词汇在所有文档中的词频\n",
    "print(features.toarray().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about' 'actually' 'also' 'am' 'an' 'and' 'any' 'anyway' 'are' 'bashers'\n",
      " 'beat' 'better' 'bit' 'bowman' 'confused' 'couple' 'devils'\n",
      " 'disappointed' 'endto' 'fans' 'finalregular' 'for' 'fun' 'game' 'games'\n",
      " 'going' 'have' 'he' 'his' 'however' 'in' 'is' 'islanders' 'jagr' 'jersey'\n",
      " 'just' 'killing' 'kind' 'lackof' 'let' 'lose' 'lot' 'lotfo' 'man'\n",
      " 'massacre' 'much' 'next' 'non' 'not' 'of' 'offun' 'out' 'pens'\n",
      " 'pittsburghers' 'playoffs' 'posts' 'praise' 'pretty' 'pulp' 'put'\n",
      " 'puzzled' 'recent' 'regular' 'relief' 'relieved' 'rule' 'season' 'see'\n",
      " 'should' 'showed' 'since' 'some' 'stats' 'sure' 'than' 'the' 'theyare'\n",
      " 'those' 'thought' 'to' 'too' 'very' 'was' 'watch' 'whyhe' 'with' 'worse'\n",
      " 'you']\n",
      "{'am': 3, 'sure': 73, 'some': 71, 'bashers': 9, 'of': 49, 'pens': 52, 'fans': 19, 'are': 8, 'pretty': 57, 'confused': 14, 'about': 0, 'the': 75, 'lackof': 38, 'any': 6, 'kind': 37, 'posts': 55, 'recent': 61, 'massacre': 44, 'devils': 16, 'actually': 1, 'bit': 12, 'puzzled': 60, 'too': 80, 'and': 5, 'relieved': 64, 'however': 29, 'going': 25, 'to': 79, 'put': 59, 'an': 4, 'endto': 18, 'non': 47, 'pittsburghers': 53, 'relief': 63, 'with': 85, 'praise': 56, 'for': 21, 'man': 43, 'theyare': 76, 'killing': 36, 'those': 77, 'worse': 86, 'than': 74, 'thought': 78, 'jagr': 33, 'just': 35, 'showed': 69, 'you': 87, 'whyhe': 84, 'is': 31, 'much': 45, 'better': 11, 'his': 28, 'regular': 62, 'season': 66, 'stats': 72, 'he': 27, 'also': 2, 'lotfo': 42, 'fun': 22, 'watch': 83, 'in': 30, 'playoffs': 54, 'bowman': 13, 'should': 68, 'let': 39, 'have': 26, 'lot': 41, 'offun': 50, 'next': 46, 'couple': 15, 'games': 24, 'since': 70, 'beat': 10, 'pulp': 58, 'out': 51, 'jersey': 34, 'anyway': 7, 'was': 82, 'very': 81, 'disappointed': 17, 'not': 48, 'see': 67, 'islanders': 32, 'lose': 40, 'finalregular': 20, 'game': 23, 'rule': 65}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidvec = TfidfVectorizer()\n",
    "features = tfidvec.fit_transform(corpus)\n",
    "print(vec.get_feature_names_out())\n",
    "print(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t0.16100106554495341\n",
      "  (0, 44)\t0.19062044846954426\n",
      "  (0, 61)\t0.19062044846954426\n",
      "  (0, 55)\t0.19062044846954426\n",
      "  (0, 37)\t0.19062044846954426\n",
      "  (0, 6)\t0.19062044846954426\n",
      "  (0, 38)\t0.19062044846954426\n",
      "  (0, 75)\t0.33109918797750876\n",
      "  (0, 0)\t0.3812408969390885\n",
      "  (0, 14)\t0.19062044846954426\n",
      "  (0, 57)\t0.19062044846954426\n",
      "  (0, 8)\t0.16100106554495341\n",
      "  (0, 19)\t0.19062044846954426\n",
      "  (0, 52)\t0.24737011242564447\n",
      "  (0, 49)\t0.4199573367512812\n",
      "  (0, 9)\t0.19062044846954426\n",
      "  (0, 71)\t0.19062044846954426\n",
      "  (0, 73)\t0.19062044846954426\n",
      "  (0, 3)\t0.13998577891709374\n",
      "  (1, 64)\t0.3451806991475409\n",
      "  (1, 5)\t0.3451806991475409\n",
      "  (1, 80)\t0.3451806991475409\n",
      "  (1, 60)\t0.3451806991475409\n",
      "  (1, 12)\t0.5830902278795688\n",
      "  (1, 1)\t0.3451806991475409\n",
      "  :\t:\n",
      "  (6, 39)\t0.20468036956732952\n",
      "  (6, 68)\t0.20468036956732952\n",
      "  (6, 13)\t0.20468036956732952\n",
      "  (6, 30)\t0.1728762987447277\n",
      "  (6, 33)\t0.1728762987447277\n",
      "  (6, 79)\t0.13280790816962715\n",
      "  (6, 25)\t0.1728762987447277\n",
      "  (6, 75)\t0.3555206416876458\n",
      "  (6, 8)\t0.1728762987447277\n",
      "  (6, 52)\t0.13280790816962715\n",
      "  (6, 49)\t0.30062190277030076\n",
      "  (7, 23)\t0.2952013096569059\n",
      "  (7, 20)\t0.2952013096569059\n",
      "  (7, 40)\t0.2952013096569059\n",
      "  (7, 32)\t0.2952013096569059\n",
      "  (7, 67)\t0.2952013096569059\n",
      "  (7, 48)\t0.2952013096569059\n",
      "  (7, 17)\t0.2952013096569059\n",
      "  (7, 81)\t0.2952013096569059\n",
      "  (7, 82)\t0.2952013096569059\n",
      "  (7, 66)\t0.24933172588050634\n",
      "  (7, 79)\t0.19154288468084643\n",
      "  (7, 75)\t0.34183430897031974\n",
      "  (8, 65)\t0.8388821959352828\n",
      "  (8, 52)\t0.5443130177965595\n"
     ]
    }
   ],
   "source": [
    "#文本矩阵，显示第i个字符串中对应词典序号为j的词汇的TF-IDF值\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2 # 卡方检验\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       " 0                  5.1               3.5                1.4               0.2\n",
       " 1                  4.9               3.0                1.4               0.2\n",
       " 2                  4.7               3.2                1.3               0.2\n",
       " 3                  4.6               3.1                1.5               0.2\n",
       " 4                  5.0               3.6                1.4               0.2\n",
       " ..                 ...               ...                ...               ...\n",
       " 145                6.7               3.0                5.2               2.3\n",
       " 146                6.3               2.5                5.0               1.9\n",
       " 147                6.5               3.0                5.2               2.0\n",
       " 148                6.2               3.4                5.4               2.3\n",
       " 149                5.9               3.0                5.1               1.8\n",
       " \n",
       " [150 rows x 4 columns],\n",
       "      0\n",
       " 0    0\n",
       " 1    0\n",
       " 2    0\n",
       " 3    0\n",
       " 4    0\n",
       " ..  ..\n",
       " 145  2\n",
       " 146  2\n",
       " 147  2\n",
       " 148  2\n",
       " 149  2\n",
       " \n",
       " [150 rows x 1 columns])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "x = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.DataFrame(iris.target)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(chi2, k=2)\n",
    "selector.fit(x, y)\n",
    "x_selected = selector.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据特征形态： (150, 4)\n",
      "特征选择后的新数据特征形态： (150, 2)\n",
      "筛选保留的特征为： Index(['petal length (cm)', 'petal width (cm)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('原始数据特征形态：',x.shape)\n",
    "print('特征选择后的新数据特征形态：',x_selected.shape)\n",
    "print('筛选保留的特征为：',x.columns[selector.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型配置优化方法：交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉验证得分：[0.96666667 1.         0.96666667 0.96666667 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libin/.virtualenvs/ml_dawei/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/libin/.virtualenvs/ml_dawei/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/libin/.virtualenvs/ml_dawei/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/libin/.virtualenvs/ml_dawei/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/libin/.virtualenvs/ml_dawei/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "scores=cross_val_score(svc, x, y, cv=5)\n",
    "print('交叉验证得分：{}'.format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉验证得分：0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "print('交叉验证得分：{}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "bc = load_breast_cancer()\n",
    "data = bc.data\n",
    "target = bc.target\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=33, test_size=0.3)\n",
    "bc_ss = StandardScaler()\n",
    "data_train = bc_ss.fit_transform(data_train)\n",
    "data_test = bc_ss.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）默认配置：采用默认配置的决策树模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9122807017543859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.86      0.92      0.89        66\n",
      "   malignant       0.95      0.90      0.93       105\n",
      "\n",
      "    accuracy                           0.91       171\n",
      "   macro avg       0.90      0.91      0.91       171\n",
      "weighted avg       0.91      0.91      0.91       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(data_train, target_train)\n",
    "predicts = dtc.predict(data_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy: ', dtc.score(data_test, target_test))\n",
    "print(classification_report(target_test,predicts,target_names=['benign','malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）使用网格搜索工具来寻找模型最优配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9415204678362573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.92      0.92      0.92        66\n",
      "   malignant       0.95      0.95      0.95       105\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.94      0.94      0.94       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n",
      "超参数配置情况: {'criterion': 'entropy', 'max_depth': 13}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold #K折交叉验证工具\n",
    "params_tree={'max_depth':range(5,15),'criterion':['entropy']}\n",
    "dtc2 = DecisionTreeClassifier()\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "grid_search_dtc=GridSearchCV(dtc2,params_tree,cv=kf)\n",
    "grid_search_dtc.fit(data_train, target_train)\n",
    "predicts = grid_search_dtc.predict(data_test)\n",
    "print ('Accuracy:',grid_search_dtc.score(data_test,target_test))\n",
    "print(classification_report(target_test,predicts,target_names=['benign','malignant']))\n",
    "print('超参数配置情况:',grid_search_dtc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "乳腺癌分类预测多模型对比演示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 逻辑回归：默认参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9707602339181286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.96      0.97      0.96        66\n",
      "   malignant       0.98      0.97      0.98       105\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(data_train, target_train)\n",
    "predicts = lr.predict(data_test)\n",
    "print ('Accuracy:',lr.score(data_test,target_test))\n",
    "print(classification_report(target_test,predicts,target_names=['benign','malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 逻辑回归：网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9707602339181286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.96      0.97      0.96        66\n",
      "   malignant       0.98      0.97      0.98       105\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n",
      "{'C': 1, 'penalty': 'l2', 'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "params_lr= {'C':[0.0001,0.001,0.01,0.1,1,10],\n",
    "            'penalty': ['l2'],\n",
    "            'tol': [1e-4,1e-5,1e-6]}\n",
    "lr2 = LogisticRegression()\n",
    "kf_lr = KFold(n_splits=10,shuffle=False)\n",
    "grid_search_lr = GridSearchCV(lr2, params_lr, cv=kf_lr)\n",
    "grid_search_lr.fit(data_train, target_train)\n",
    "predicts = grid_search_lr.predict(data_test)\n",
    "print ('Accuracy:',grid_search_lr.score(data_test,target_test))\n",
    "print(classification_report(target_test,predicts,target_names=['benign','malignant']))\n",
    "print(grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. SVC: default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9766081871345029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.97      0.97      0.97        66\n",
      "   malignant       0.98      0.98      0.98       105\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libin/.virtualenvs/ml_dawei/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(data_train, target_train)\n",
    "predicts = lsvc.predict(data_test)\n",
    "print ('Accuracy:',lsvc.score(data_test,target_test))\n",
    "print(classification_report(target_test,predicts,target_names=['benign','malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. SVC: 网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824561403508771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.98      0.97      0.98        66\n",
      "   malignant       0.98      0.99      0.99       105\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n",
      "{'C': 4.5, 'gamma': 0.002}\n"
     ]
    }
   ],
   "source": [
    "params_svc={'C':[4.5,5,5.5,6],\n",
    "            'gamma':[0.0009,0.001,0.0011,0.002]}\n",
    "svc = SVC()\n",
    "kf=KFold(n_splits=10,shuffle=False)\n",
    "grid_search_svc=GridSearchCV(svc,params_svc,cv=kf)\n",
    "grid_search_svc.fit(data_train, target_train)\n",
    "predicts = grid_search_svc.predict(data_test)\n",
    "print ('Accuracy:',grid_search_svc.score(data_test,target_test))\n",
    "print(classification_report(target_test,predicts,target_names=['benign','malignant']))\n",
    "print(grid_search_svc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 决策树分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9298245614035088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.89      0.94      0.91        66\n",
      "   malignant       0.96      0.92      0.94       105\n",
      "\n",
      "    accuracy                           0.93       171\n",
      "   macro avg       0.92      0.93      0.93       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(data_train, target_train)\n",
    "predicts = dtc.predict(data_test)\n",
    "print ('Accuracy:',dtc.score(data_test,target_test))\n",
    "print(classification_report(target_test,predicts,target_names=['benign','malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 决策树：网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9532163742690059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.93      0.95      0.94        66\n",
      "   malignant       0.97      0.95      0.96       105\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.95      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "params_tree={'max_depth':range(5,15),'criterion':['entropy']}\n",
    "dtc = DecisionTreeClassifier()\n",
    "kf=KFold(n_splits=10,shuffle=False)\n",
    "grid_search_dtc=GridSearchCV(dtc,params_tree,cv=kf)\n",
    "grid_search_dtc.fit(data_train, target_train)\n",
    "predicts = grid_search_dtc.predict(data_test)\n",
    "print ('Accuracy:',grid_search_dtc.score(data_test,target_test))\n",
    "print(classification_report(target_test,predicts,target_names=['benign','malignant']))\n",
    "print(grid_search_dtc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC with grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicts: 0\n",
      "target: 0\n"
     ]
    }
   ],
   "source": [
    "try_idx = 100\n",
    "data_try = data[try_idx].reshape(1, -1)\n",
    "data_try\n",
    "predicts = grid_search_svc.predict(data_try)\n",
    "print(\"predicts:\", predicts[0])\n",
    "print(\"target:\", target[try_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_dawei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
